<!DOCTYPE HTML>
<!--
	Strata by HTML5 UP
	html5up.net | @n33co
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Responsible AI international community to reduce bias in AI music generation and analysis</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="assets/css/main.css" />
		<!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->
	</head>
	<body id="top">

		<!-- Header -->
			<header id="header">
				<h0><strong>Music<br>RAI</strong></h0><br />
			</header>

		<!-- Main -->
			<div id="main">

				<!-- One -->
					<section id="one">
						<header class="major">
						
						<!--<h1>Duxianqin Workshop 2019</h1>-->
						</header>

<a id="projectinfo"><h1>About the MusicRAI Research Project</h1></a>
						
						<p>This 12 month project <strong>"Responsible AI international community to reduce bias in AI music generation and analysis"</strong> will build an international community to address Responsible AI (RAI) challenges of bias in AI music generation and analysis.</p>
						<p>The aim of the project is to explore ways to tackle current over-reliance on huge training datasets for deep learning leads to AI models biased towards Western classical and pop music and marginalises other music genres. We will bring together an international and interdisciplinary team of researchers, musicians, and industry experts to make available AI tools, expertise, and datasets which improve access to marginalised music genres. This will directly benefit musicians and audiences engaging with a wider range of musical genres and benefits creative industries by offering new forms of music consumption.</p>

						<h1>Ethical and Responsible AI Music Making Workshop 2024</h1>
						
						<p>We held a one-day workshop on Responsible Music AI with a focus on bias in AI music generation systems on 17th July 2024 at the Creative Computing Institute, University of the Arts London, Holborn, London. </p>

<p>We brought together over 100 people to form an interdisciplinary community of musicians, academics, and stakeholders to collaboratively identify the potential and challenges for using low-resource models and small datasets in musical practice. The workshop consisted of publicly streamed discussion panels, presentations of participants’ work, and brainstorming sessions on the future of AI and marginalised music. The event was followed by an evening reception featuring live performances sing AI and small datasets of music. </p>

<p>In the morning sessions we focussed on sharing and identifying current practices and challenges for AI music making with small datasets. The afternoon was dedicated to exploring opportunities and practical solutions to using small and marginalised datasets of music and other audio with AI. This forms the start of an international network and roadmap for a new ecosystem that we will build to rapidly open small music datasets and low-resource AI approaches to more wider use in music making and analysis. </p>

<table>
    <tbody>

        <tr>
            <td>
                <b style="font-size: 1.1em;">Panel Discussion</b> [<a href = "https://youtube.com/live/cWx8h4xhY8g">youtube recording</a>]
                <div>Challenges and Opportunities for Music Creation</div><div style="padding-top: 0.5em;">Panelists:</div><ul style="list-style: none;margin-bottom: 0; padding-left:0;">
<li>François Pachet (Founder)</li>
<li>Rebecca Fiebrink (University of the Arts London)</li>
<li>Nuno Correia (Tallinn University)</li>
<li>Phoenix Perry (University of the Arts London)</li>
</ul><div style="padding-top: 0.5em;">Moderator:</div><ul style="list-style: none;margin-bottom: 0;padding-left:0;">
<li>Nick Bryan-Kinns (University of the Arts London)</li>



</ul>
            </td>
        </tr>
        
        <tr>
            <td>
                <b style="font-size: 1.1em;">Panel Discussion (hybrid)</b> [<a href = "https://youtube.com/live/Ch21OshaMsw">youtube recording</a>]
                <div>The Future of Music Creation</div><div style="padding-top: 0.5em;">Panelists:</div><ul style="list-style: none;margin-bottom: 0;padding-left:0;">
<li>Paul McCabe (Roland and AI For Music)</li>
<li>Hazel Savage (SoundCloud and Musiio)</li>
<li>Daisy Rosenblum (University of British Columbia)</li>
<li>CJ Carr (Dadabots)</li>
</ul><div style="padding-top: 0.5em;">Moderator:</div><ul style="list-style: none;margin-bottom: 0;padding-left:0;">
<li>Nick Bryan-Kinns (University of the Arts London)</li>



</ul>
            </td>
        </tr>
        <tr>
            <td>
                <div style="padding-top: 0.5em;"><b style="font-size: 1.1em;">Live Performances</b></div><ul style="list-style: none;margin-bottom: 0;padding-left:0;">
<li>digital selves</li>
<li>Portrait XO</li>
<li>Dadabots</li>
<li>Gabriel Vigliensoni</li>

</ul>
            </td>
    </tr></tbody>
</table>

<p><span class="image left"><img src="images/fulls/room_lores.jpeg" alt="Workshop 17 July 2024" /></span></p><div style="clear: left"></div>
    <p><span class="image left"><img src="images/fulls/case_study_lores.JPG" alt="Case study presentation" /></span><span class="image left"><img src="images/fulls/panel1_lores.JPG" alt="Panel discussion" /></span></p>

        <p><span class="image left"><img src="images/fulls/performer_1_lores.JPG" alt="digital selves" /></span><span class="image left"><img src="images/fulls/performer_2_lores.JPG" alt="Gabriel Vigliensoni" /></span><span class="image left"><img src="images/fulls/performer_3_lores.JPG" alt="Dadabots" /></span><span class="image left"><img src="images/fulls/performer_4_lores.JPG" alt="Portrait XO" /></span></p> <div style="clear: left">

<hr>

						<h2>Team</h2>
						<p>
							Lead: <b>Prof. Nick Bryan-Kinns</b> (University of the Arts London, UK; UAL)<br>
<b>Prof. Rebecca Fiebrink</b> (UAL) <br>
<b>Dr. Phoenix Perry</b> (UAL) <br>
<b>Anna Wszeborowska</b> (UAL) <br>
<b>Prof. Zijin Li</b> (Central Conservatory of Music, China; CCoM) <br>
<b>Dr. Nuno Correia</b> (Tallinn University, Estonia; TU) <br>
<b>Dr. Alex Lerch</b> (Georgia Tech, USA; GT) <br>
<b>Prof. Sid Fels</b> (University of British Columbia, Canada; UBC) <br>
<b>Dr. Gabriel Vigliensoni</b> (Concordia University, Canada; CU) <br>
<b>Dr. Andrei Coronel</b> and <b>Dr. Raphael Alampay</b> (Ateneo de Manila University, Philippines; AdMU) <br>
<b>Prof. Rikard Lindell</b> (Dalarna University, Sweden; DU)
						</p>

						<h2>Partners</h2>
						<p>
							<b>Music Hackspace</b> (UK)<br>
							<b>DAACI</b> (UK)<br>
							<b>Steinberg</b> (Germany)<br>
							<b>Bela</b> (UK)<br>
						</p>

						<h2>Objectives</h2>
							<ul>
							<li>To bring together and grow the international community of researchers, creative practitioners, and AI experts interested in using musical genres marginalised by current AI systems (AI marginalisation) as datasets for AI music making practice and research.</li>
							<li>To establish an open repository of marginalised musical genre datasets for use in AI.</li>
							<li>To bring together and make available methods and tools for how artists might use techniques such as low-resource deep learning models to generate music using marginalized music genres.</li>
							<li>To commission a small number of speculative artistic projects resulting in international showcase of generative AI music using marginalised musical genres.</li>
							<li>To explore the translational potential of the AI techniques identified in this project to other creative practices.</li>
						</ul>

<h2>Contact</h2>
<p>To get involved please contact Prof. Nick Bryan-Kinns <a href = "mailto:n.bryankinns@arts.ac.uk">n.bryankinns@arts.ac.uk</a></p>

						<h2>Funding</h2>

						<p>Funded by <a href = "https://www.rai.ac.uk">Responsible Artificial Intelligence (RAI) UK</a> <a href = "https://www.rai.ac.uk/international-partnerships">International Partnerships</a> (UKRI EPSRC grant reference EP/Y009800/1)</p>
						
														
					</section>
								
<hr>
					
				       <h6>Template: <a href="http://html5up.net/">HTML5 UP</a> </h6>

			</div>

		<!-- Footer -->
		
		<!--
			<footer id="footer">
				<ul class="icons">
					<li><a href="https://twitter.com/nickbknickbk" class="icon fa-twitter"><span class="label">Twitter</span></a></li>
				</ul>
				
				<ul class="copyright">
                <h6><strong>Supported by:</strong><br /> <a href = "http://www.ccmusic.edu.cn">China Conservatory of Music</a><br /> <a href = "http://www.mat.qmul.ac.uk">EPSRC+AHRC Media and Arts Technology CDT</a><br /><a href = "http://qmul.ac.uk">Queen Mary University of London</a></h6> 

				</ul>
			</footer>
            -->    
		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.poptrox.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
			<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="assets/js/main.js"></script>

	</body>
</html>